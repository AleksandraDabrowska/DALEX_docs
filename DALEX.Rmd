--- 
title: "DALEX: Descriptive mAchine Learning EXplanations"
author: "MI2DataLab"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
split_by: section+number
output: bookdown::gitbook
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
github-repo: rstudio/bookdown-demo
description: "Do not trust a black-box model. Unless it explains itself."
--- 
```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

# Introduction

Machine Learning models are widely used and have various applications in classification or regression tasks. Due to increasing computational power, availability of new data sources and new methods, ML models are more and more complex. Models created with techniques like boosting, bagging of neural networks are true black boxes. It is hard to trace the link between input variables and model outcomes. They are use because of high performance, but lack of interpretability is one of their weakest sides.

In many applications we need to know, understand or prove how input variables are used in the model and what impact do they have on final model prediction.
DALEX is a set of tools that help to understand how complex models are working.

## Notation

This book describes explainers for different machine learning models. Some of these explainers are created by different research groups with different applications in mind.

To keep the notation consistent:

- $x = (x_1, ..., x_p)$ stands for a vector of $p$ variables/predictors. 
- $y$ stands for a vector with target variable. In some applications it will be a continuous variable in others it will be a binary variable.
- $n$ stands for number of observations.
- $f(x, \theta)$ stands for a model. We are considering models that are characterized by a set of parameters $\theta$. In some applications $\theta$ is a low level space of parameters - nice parametric models, in some applications $\theta$ may have a very complex structure.
- $\lambda$ stands for model meta-parameters which are not being directly optimized (like number of trees, max depth, some penalties etc.).
- $g(x)$ stands for a function that pre-process variables. In some applications it may be a standardisation or other pre-processing. 


![](images/model01.jpg)


## Use case - Human Resources Analytics

To ilustrate applications of DALEX to binary classification problems we will use a dataset from Kaggle competition [Human Resources Analytics]( https://www.kaggle.com/ludobenistant/hr-analytics/data). This dataset is avaliable in the **breakDown** package [@breakDown].

```{r eval=FALSE}
library("breakDown")
head(HR_data)
```

```{r hr_data, echo=FALSE}
library("breakDown")
knitr::kable(
  head(HR_data),
  caption = 'HR_data dataset from Kaggle competition Human Resources Analytics'
  )
```

### Logistic regression

In the following chapters to present explainers for logistic regression models we will use `HR_glm_model`.

```{r}
HR_glm_model <- glm(left~., data = HR_data, family = "binomial")
summary(HR_glm_model)
```

Models used in this doccumentation are accessible via **archivist** package. To download the `HR_glm_model` model use the following instruction. 
```
archivist::aread("pbiecek/DALEX/arepo/8fe19a108faf3ddfcabc3de3a0693234")
```

### Random forest

In the following chapters to present explainers for random forest models we will use `HR_fr_model`.

```{r}
library("randomForest")
set.seed(1313)
HR_data$left <- factor(HR_data$left)
HR_rf_model <- randomForest(left~., data = HR_data, ntree = 100)
HR_rf_model
```

Models used in this doccumentation are accessible via **archivist** package. To download the `HR_rf_model` model use the following instruction. 
```
archivist::aread("pbiecek/DALEX/arepo/419d550a92fab6a5f28650130991e2cd")
```


## Use case - Wine quality

To ilustrate applications of DALEX to regression problems we will use a Wine quality dataset from Kaggle competition [UC Irvine Machine Learning Repository](http://mlr.cs.umass.edu/ml/). 

```{r eval=FALSE}
url <- 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv'
wine <- read.table(url, header = TRUE, sep = ";")
head(wine)
```

```{r wineQuality, echo=FALSE}
url <- 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv'
wine <- read.table(url, header = TRUE, sep = ";")
knitr::kable(
  head(wine),
  caption = 'Wine quality dataset from UC Irvine Machine Learning Repository'
  )
```

### Linear regression

In the following chapters to present explainers for gaussian regression models we will use `wine_lm_model`.

```{r}
wine_lm_model <- lm(quality ~ fixed.acidity + volatile.acidity + citric.acid + residual.sugar + chlorides + free.sulfur.dioxide + total.sulfur.dioxide + density + pH + sulphates + alcohol,
               data = wine)
```

Models used in this doccumentation are accessible via **archivist** package. To download the `wine_lm_model` model use the following instruction. 
```
archivist::aread("pbiecek/DALEX/arepo/b99a3d58016e2677221019652cff047f")
```


## Reproducibility

Packages are changing quite fast, especially in actively developed areas. 
Below you will find list of packages that were installed on my computer when I was preparing this documentation.

It is likely that some of described packages will change names of functions or arguments or structure of results. Use the version listed below to reproduce results form this book.

Note, that results, models and plots created in are were recorded with the **archivist** package [@archivist]. Use archivist links to retrieve their binary copies directly to your R console.


```{r}
devtools::session_info()
```

## Trivia

![](images/dalex01small.jpg)

[The Daleks](https://en.wikipedia.org/wiki/Dalek) are a fictional extraterrestrial race portrayed in the [Doctor Who](https://en.wikipedia.org/wiki/Doctor_Who) BBC series. Rather dim aliens, known to repeat the phrase *Explain!* very often.

```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown'
), 'packages.bib')
```



<!--chapter:end:index.Rmd-->

```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```
# Global structure

## Forest plots

[Forest plots](https://en.wikipedia.org/wiki/Forest_plot) were initially used in the meta analysis to visualise effects in different studies. But now they are frequently used to present summary characteristics for models with linear structure like these created with `lm` or `glm` functions.

There are various implementations of forest plots in R. Below we present examples for a glm model.

```{r}
library("breakDown")
HR_glm_model <- glm(left~., data = HR_data, family = "binomial")


#HR_glm_model <- archivist::aread("pbiecek/DALEX/arepo/8fe19a108faf3ddfcabc3de3a0693234")
```

In the package **forestmodel** (see [@forestmodel]) one can use `forest_model()` function to draw a forest plot. This package is based on the **broom** package (see [@broom]) and this is why it handles a large variety of different regression models. An example for `glm`.

```{r forestmodel, fig.width=10, fig.width=8, fig.cap='Forest plot created with forestmodel package'}
library("forestmodel")
forest_model(HR_glm_model)
```

In the package **sjPlot** (see [@sjPlot]) one can use `sjp.*()` to visualise structure of a `*` model or a wrapper `plot_model()`. Here is an example for `glm` model.

```{r sjpglm, fig.width=10, fig.width=8, fig.cap='Forest plot created with sjPlot package'}
library("sjPlot")
plot_model(HR_glm_model, type = "est", sort.est = TRUE)
```

**Note!** 

The **forestmodel** package handles factor variables in a better way while the plots from **sjPlot** are easier to read.


<!--chapter:end:01-global.Rmd-->

```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```
# Conditional structure

## Partial Dependence Plots

Partial Dependence Plots (see **pdp** package [@pdp]) for a black box $f(x; \theta)$ calculates the expected output given a selected variable.

$$
p_i(x_i) = E_{x_{-i}}[ f(x^i, x^{-i}; \theta) ]
$$

Of course this expectation cannot be calculated directly as we do not know fully the $f()$ neither the distribution of $x_{-i}$. This value is estimated by 

$$
\hat p_i(x_i) = \frac{1}{n} \sum_{j=1}^{n} f(x^i_j, x_j^{-i}, \hat \theta) 
$$


Let's see an example for the model `HR_rf_model`. Below we are using `pdp::partial` function to calculate pdp curve for variable `satisfaction_level`. Then the curve is plotted with `plotPartial` (based on `lattice`) or `autoplot` (based on `ggplot2`).

```{r, message=FALSE, warning=FALSE}
library("pdp")
library("randomForest")
library("breakDown")

HR_rf_model <- randomForest(left~., data = breakDown::HR_data, ntree = 100)

part <- partial(HR_rf_model, "satisfaction_level")

plotPartial(part)

library("ggplot2")
autoplot(part)
```

## Individual Conditional Expectation Plot

Individual Conditional Expectations (ICE) may be considered as an extension of the PDP curves (see **ICEbox** package [@ICEbox]).
Instead of plotting expected value over all observations, for ICE we are plotting individual conditional model responses. Average of ICE curves results in PDP curve.

An ICE curve for observation $k$ over variable $i$ may be defined as

$$
ice_k(x_i) = f(x^i, x_k^{-i}; \theta) 
$$

ICE curves can be plotted with `pdp` package. Note that curves may be cantered in a given point, this helps in identification of possible interactions.

```{r, message=FALSE, warning=FALSE}
library("pdp")
library("randomForest")
library("breakDown")
library("ggplot2")

HR_rf_model <- randomForest(left~., data = breakDown::HR_data, ntree = 100)

part_rf_satisfaction <- partial(HR_rf_model, "satisfaction_level")

part_rf_satisfaction <- partial(HR_rf_model, pred.var = "satisfaction_level", ice = TRUE)
plotPartial(part_rf_satisfaction, rug = TRUE, train = HR_data, alpha = 0.2)
autoplot(part_rf_satisfaction, center = TRUE, alpha = 0.2, rug = TRUE, train = HR_data)
```

Or with the `ICEbox` package.

```{r, message=FALSE, warning=FALSE}
library("ICEbox")
part_rf_satisfaction = ice(object = HR_rf_model, X = HR_data, y = HR_data$satisfaction_level, predictor = "satisfaction_level", frac_to_build = .1)
plot(part_rf_satisfaction)
```

As ICE curves are useful tool for identification of interactions, these individual curves may be clustered with the `clusterICE` function.

```{r, message=FALSE, warning=FALSE}
clusterICE(part_rf_satisfaction, nClusters = 3, plot_legend = TRUE, center = TRUE)
```

## Factor Merger

The package `ICEbox` is not working for factor variables while the `pdp` package returns plots that are hard to interpret.

An interesting tool that helps to understand what is happening with factor variables is the **factorMerger** package (see [@factorMerger]).

Here we have Merging Path Plot for a factor variable `sales`.

```{r, message=FALSE, warning=FALSE, fig.width=12, fig.height=8}
library("factorMerger")
path <- mergeFactors(HR_data$left, HR_data$sales, method = "fast-adaptive", family = "binomial", abbreviate = FALSE)
plot(path, panel = "all")
```

Note that you can use the `factorMerger` package to understand predictions calculated with a black-box model. The random forest model `HR_rf_model` returns continuous response. But the `factorMerger` works for such variables as well.

In the top right panel one mey see the distribution of predictions for the selected group.

```{r, message=FALSE, warning=FALSE, fig.width=12, fig.height=8}

HR_data$left_predicted <- predict(HR_rf_model)

path <- mergeFactors(HR_data$left_predicted, HR_data$sales, method = "fast-adaptive",  abbreviate = FALSE)
plot(path, panel = "all", responsePanel = "boxplot")
```

## ALEPlot

**ALEPlot** package [@ALEPlot]



<!--chapter:end:02-conditional.Rmd-->

```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```
# Local structure

Explainers presented in this chapter are designed to better understand the local structure of a black box in a single point. Example applications:

* explanations for predictions. Can be used to validate if a specific prediction is not accidental, is it based on variables important in the domain.
* examination of curvature around a specific point (single observation). Can be used to determine the strength of influence onto a final model. Is it an outlier?

There are more interesting applications. Find out some of them in the *Why Should I Trust You?* article [@lime].

## Local Interpretable (Model-agnostic) Visual Explanations 

The **live** package (see [@live]) may be seen as an extension of the lime method (see [@lime]). It is based on **mlr** general framework for training of machine learning models (see more [@mlr]).

Let's see an example. We will use the `HR_rf_model` trained with the **randomForest** package on Human Resources Analytics data.

Around a selected point we will fit a linear model.

```{r live_train}
library("live")
library("randomForest")
library("breakDown")

HR_data$left <- as.numeric(as.character(HR_data$left))

HR_rf_model <- randomForest(left~., data = HR_data,
ntree=100)

similar <- sample_locally(data = HR_data, explained_instance = HR_data[1,], explained_var = "left", size = 2000)
similar <- add_predictions(HR_data, similar, HR_rf_model)
trained <- fit_explanation( live_object = similar, white_box = "regr.lm", selection = FALSE)
```

Fitted model may be plotted with *waterfall plot* ...

```{r live_water}
plot_explanation(trained, "waterfallplot", explained_instance = HR_data[1,])
```

... or *forest plot* ...

```{r live_forest}
plot_explanation(trained, "forestplot", explained_instance = HR_data[1,])
```

For more details consult the following vignette.

![](https://raw.githubusercontent.com/MI2DataLab/live/master/cheatsheets/liveCheatsheet.png)


## breakDown

[@breakDown]


<!--chapter:end:03-local.Rmd-->

```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```
# Model performance

We have finished a nice book.


You can label chapter and section titles using `{#label}` after them, e.g., we can reference Chapter \@ref(intro). If you do not manually label them, there will be automatic labels anyway, e.g., Chapter \@ref(methods).

Figures and tables with captions will be placed in `figure` and `table` environments, respectively.

```{r nice-fig, fig.cap='Here is a nice figure!', out.width='80%', fig.asp=.75, fig.align='center'}
par(mar = c(4, 4, .1, .1))
plot(pressure, type = 'b', pch = 19)
```

Reference a figure by its code chunk label with the `fig:` prefix, e.g., see Figure \@ref(fig:nice-fig). Similarly, you can reference tables generated from `knitr::kable()`, e.g., see Table \@ref(tab:nice-tab).

```{r nice-tab, tidy=FALSE}
knitr::kable(
  head(iris, 20), caption = 'Here is a nice table!',
  booktabs = TRUE
)
```

You can write citations, too. For example, we are using the **bookdown** package [@R-bookdown] in this sample book, which was built on top of R Markdown and **knitr** [@xie2015].

<!--chapter:end:04-performance.Rmd-->

