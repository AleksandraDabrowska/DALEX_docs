# Architecture of DALEX {#architecture}

In order to easily explore the structure of a black-box model we need to have an easy to use tool with unified interface.

This is why DALEX architecture is simple and consistent. Actually there are only tree rules that should be remembered and one is ready to use this tool.

* First step is to use the `explain()` function to enrich a black-box model with additional metadata required by explainers. Different explainers require different additional inputs. Find the list of required elements in Section \@ref(explainFunction).
* Second step is to use an explainer function that calculates required explanations. Explainers are listed in Chapter \@ref(modelUnderstanding) and \@ref(predictionUnderstanding).
* Third step is to use generic `print()` or `plot()` function to see the explainer. Both functions work for one or model models.


These three steps are presented in the Figure 2.1.

<p><span class="marginnote">Figure 2.1. The overview of DALEX architecture. <br/><br/>
*A)* Any predictive model with defined input $x$ and output $y_{raw} \in \mathcal R$ may be used. <br/><br/>
*B)* Models are first enriched in additional metadata, like a function that calculates predictions, test data, and other components. The `explain()` function creates an object of the class `explainer`, that can bu used in further processing.<br/><br/> 
*C)* Based on the `explainer` various summaries may be calculated. <br/>
Each explainer calculates a numerical summaries that can be plotted with generic `plot()` function.
</span>
<img src="images/architecture.png"/></p>




## Notation

This book describes explainers for different machine learning models. Some of these explainers are created by different research groups with different applications in mind.

To keep the notation consistent:

- $x = (x_1, ..., x_p)$ stands for a vector of $p$ variables/predictors. 
- $y$ stands for a vector with target variable. In some applications it will be a continuous variable in others it will be a binary variable.
- $n$ stands for number of observations.
- $f(x, \theta)$ stands for a model. We are considering models that are characterized by a set of parameters $\theta$. In some applications $\theta$ is a low level space of parameters - nice parametric models, in some applications $\theta$ may have a very complex structure.
- $\lambda$ stands for model meta-parameters which are not being directly optimized (like number of trees, max depth, some penalties etc.).
- $g(x)$ stands for a function that pre-process variables. In some applications it may be a standardisation or other pre-processing. 


![](images/model01.jpg)

## How to use the `explain()` function {#explainFunction}



* `model`	 object - a model to be explained
* `data`	data.frame or matrix - data that was used for fitting. If not provided then will be extracted from the model
* `y`	 numeric vector with outputs / scores. Currently used only by variable_dropout() explainer.
* `predict_function`	 function that takes two arguments: model and new data and returns numeric vector with predictions
* `link`	function - a transformation/link function that shall be applied to raw model predictions
* `label`	 character - the name of the model. By default it's extracted from the 'class' attribute of the model



## Use case - Human Resources Analytics

To ilustrate applications of DALEX to binary classification problems we will use a dataset from Kaggle competition [Human Resources Analytics]( https://www.kaggle.com/ludobenistant/hr-analytics/data). This dataset is avaliable in the **breakDown** package [@breakDown].

```{r eval=FALSE}
library("breakDown")
head(HR_data)
```

```{r hr_data, echo=FALSE}
library("breakDown")
knitr::kable(
  head(HR_data),
  caption = 'HR_data dataset from Kaggle competition Human Resources Analytics'
  )
```

### Logistic regression

In the following chapters to present explainers for logistic regression models we will use `HR_glm_model`.

```{r}
HR_glm_model <- glm(left~., data = HR_data, family = "binomial")
summary(HR_glm_model)
```

Models used in this doccumentation are accessible via **archivist** package. To download the `HR_glm_model` model use the following instruction. 
```
archivist::aread("pbiecek/DALEX/arepo/8fe19a108faf3ddfcabc3de3a0693234")
```

### Random forest

In the following chapters to present explainers for random forest models we will use `HR_fr_model`.

```{r}
library("randomForest")
set.seed(1313)
HR_data$left <- factor(HR_data$left)
HR_rf_model <- randomForest(left~., data = HR_data, ntree = 100)
HR_rf_model
```

Models used in this doccumentation are accessible via **archivist** package. To download the `HR_rf_model` model use the following instruction. 
```
archivist::aread("pbiecek/DALEX/arepo/419d550a92fab6a5f28650130991e2cd")
```


## Use case - Wine quality

To ilustrate applications of DALEX to regression problems we will use a Wine quality dataset from Kaggle competition [UC Irvine Machine Learning Repository](http://mlr.cs.umass.edu/ml/). 

```{r eval=FALSE}
url <- 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv'
wine <- read.table(url, header = TRUE, sep = ";")
head(wine)
```

```{r wineQuality, echo=FALSE}
url <- 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv'
wine <- read.table(url, header = TRUE, sep = ";")
knitr::kable(
  head(wine),
  caption = 'Wine quality dataset from UC Irvine Machine Learning Repository'
  )
```

### Linear regression

In the following chapters to present explainers for gaussian regression models we will use `wine_lm_model`.

```{r}
wine_lm_model <- lm(quality ~ fixed.acidity + volatile.acidity + citric.acid + residual.sugar + chlorides + free.sulfur.dioxide + total.sulfur.dioxide + density + pH + sulphates + alcohol,
               data = wine)
```

Models used in this doccumentation are accessible via **archivist** package. To download the `wine_lm_model` model use the following instruction. 
```
archivist::aread("pbiecek/DALEX/arepo/b99a3d58016e2677221019652cff047f")
```
