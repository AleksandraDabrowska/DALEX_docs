@Book{xie2015,
  title = {Dynamic Documents with {R} and knitr},
  author = {Yihui Xie},
  publisher = {Chapman and Hall/CRC},
  address = {Boca Raton, Florida},
  year = {2015},
  edition = {2nd},
  note = {ISBN 978-1498716963},
  url = {http://yihui.name/knitr/},
}

@Book{ggplot2,
    author = {Hadley Wickham},
    title = {ggplot2: Elegant Graphics for Data Analysis},
    publisher = {Springer-Verlag New York},
    year = {2009},
    isbn = {978-0-387-98140-6},
    url = {http://ggplot2.org},
  }

 @article{AlphaGoZero, title={Mastering the game of Go without human knowledge}, volume={550}, ISSN={0028-0836, 1476-4687}, DOI={10.1038/nature24270}, number={7676}, journal={Nature}, author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and et al.}, year={2017}, month={Oct}, pages={354–359}}

  @Article{archivist,
    title = {{archivist}: An {R} Package for Managing, Recording and Restoring Data Analysis Results},
    author = {Przemyslaw Biecek and Marcin Kosinski},
    journal = {Journal of Statistical Software},
    year = {2017},
    volume = {82},
    number = {11},
    pages = {1--28},
    doi = {10.18637/jss.v082.i11},
  }


 @Manual{randomForestExplainer,
    title = {randomForestExplainer: A set of tools to understand what is happening inside a Random Forest},
    author = {Aleksandra Paluszynska and Przemyslaw Biecek},
    year = {2017},
    note = {R package version 0.9},
    url = {https://github.com/MI2DataLab/randomForestExplainer},
  }
 @Manual{xgboostExplainer,
    title = {xgboostExplainer: An R package that makes xgboost models fully interpretable},
    author = {David Foster},
    year = {2017},
    note = {R package version 0.1},
    url = {https://github.com/AppliedDataSciencePartners/xgboostExplainer/},
  }
 @Manual{live,
    title = {live: Local Interpretable (Model-agnostic) Visual Explanations},
    author = {Mateusz Staniak and Przemyslaw Biecek},
    year = {2017},
    note = {R package version 1.4.0},
    url = {https://github.com/MI2DataLab/live},
  }

 @Manual{forestplot,
    title = {forestplot: Advanced Forest Plot Using 'grid' Graphics},
    author = {Max Gordon and Thomas Lumley},
    year = {2017},
    note = {R package version 1.7.2},
    url = {https://CRAN.R-project.org/package=forestplot},
  }

  @Article{ICEbox,
    title = {Peeking Inside the Black Box: Visualizing Statistical Learning With Plots of Individual Conditional Expectation},
    author = {Alex Goldstein and Adam Kapelner and Justin Bleich and Emil Pitkin},
    journal = {Journal of Computational and Graphical Statistics},
    volume = {24},
    number = {1},
    pages = {44--65},
    doi = {10.1080/10618600.2014.907095},
    year = {2015},
  }


  @Article{pdp,
    title = {pdp: An R Package for Constructing Partial Dependence Plots},
    author = {Brandon M. Greenwell},
    journal = {The R Journal},
    year = {2017},
    volume = {9},
    number = {1},
    pages = {421--436},
    url = {https://journal.r-project.org/archive/2017/RJ-2017-016/index.html},
  }


   @Manual{factorMerger,
    title = {factorMerger: Hierarchical Algorithm for Post-Hoc Testing},
    author = {Agnieszka Sitko and Przemyslaw Biecek},
    year = {2017},
    note = {R package version 0.3.4},
    url = {https://github.com/MI2DataLab/factorMerger},
  }

  @Manual{randomForestExplainer,
    title = {randomForestExplainer: Explaining and Visualizing Random Forests in Terms of Variable
Importance},
    author = {Aleksandra Paluszynska and Przemyslaw Biecek},
    year = {2017},
    note = {R package version 0.9},
    url = {https://CRAN.R-project.org/package=randomForestExplainer},
  }

@Manual{breakDown,
    title = {breakDown: BreakDown Plots},
    author = {Przemyslaw Biecek},
    year = {2017},
    note = {R package version 0.1.2},
    url = {https://CRAN.R-project.org/package=breakDown},
  }

 @Manual{sjPlot,
    title = {sjPlot: Data Visualization for Statistics in Social Science},
    author = {Daniel Lüdecke},
    year = {2017},
    note = {R package version 2.4.0},
    url = {https://CRAN.R-project.org/package=sjPlot},
  }

  @Manual{forestmodel,
    title = {forestmodel: Forest Plots from Regression Models},
    author = {Nick Kennedy},
    year = {2017},
    note = {R package version 0.4.3},
    url = {https://CRAN.R-project.org/package=forestmodel},
  }

 @Manual{broom,
    title = {broom: Convert Statistical Analysis Objects into Tidy Data Frames},
    author = {David Robinson},
    year = {2017},
    note = {R package version 0.4.3},
    url = {https://CRAN.R-project.org/package=broom},
  }

 @Manual{live,
    title = {live: Local Interpretable (Model-Agnostic) Visual Explanations},
    year = {2017},
    author = {Mateusz Staniak and Przemysław Biecek},
    note = {R package version 0.2.0},
  }

 @Article{mlr,
    title = {{mlr}: Machine Learning in R},
    author = {Bernd Bischl and Michel Lang and Lars Kotthoff and Julia Schiffner and Jakob Richter and Erich Studerus and Giuseppe Casalicchio and Zachary M. Jones},
    journal = {Journal of Machine Learning Research},
    year = {2016},
    volume = {17},
    number = {170},
    pages = {1-5},
    url = {http://jmlr.org/papers/v17/15-066.html},
  }

 @inbook{lime,
 title={“Why Should I Trust You?”: Explaining the Predictions of Any Classifier},
 ISBN={978-1-4503-4232-2},
 url={http://dl.acm.org/citation.cfm?doid=2939672.2939778},
 DOI={10.1145/2939672.2939778},
 publisher={ACM Press},
 author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
 year={2016},
 pages={1135–1144}
 }

  @Manual{ALEPlot,
    title = {ALEPlot: Accumulated Local Effects (ALE) Plots and Partial Dependence
(PD) Plots},
    author = {Dan Apley},
    year = {2017},
    note = {R package version 1.0},
    url = {https://CRAN.R-project.org/package=ALEPlot},
  }

@inproceedings{Strumbelj,
	author = {\v{S}trumbelj, Erik and Kononenko, Igor},
	title = {A General Method for Visualizing and Explaining Black-box Regression Models},
	booktitle = {Proceedings of the 10th International Conference on Adaptive and Natural Computing Algorithms - Volume Part II},
	series = {ICANNGA'11},
	year = {2011},
	isbn = {978-3-642-20266-7},
	location = {Ljubljana, Slovenia},
	pages = {21--30},
	numpages = {10},
	url = {http://dl.acm.org/citation.cfm?id=1997005.1997009},
	acmid = {1997009},
	publisher = {Springer-Verlag},
	address = {Berlin, Heidelberg},
	keywords = {SVM, neural networks, prediction, transparency},
}

@INPROCEEDINGS{nnet_vis,
	author={F. Y. Tzeng and K. L. Ma},
	booktitle={VIS 05. IEEE Visualization, 2005.},
	title={Opening the black box - data driven visualization of neural networks},
	year={2005},
	pages={383-390},
	keywords={backpropagation;data visualisation;neural nets;problem solving;artificial neural network;black box opening;classification task;data driven visualization;human nervous system;machine learning tool;problem solving;Artificial neural networks;Biological neural networks;Computer networks;Data visualization;Humans;Neural network hardware;Neural networks;Neurons;Power system modeling;Software},
	doi={10.1109/VISUAL.2005.1532820},
	month={Oct},
}

@ARTICLE{magix,
	author = {{Puri}, N. and {Gupta}, P. and {Agarwal}, P. and {Verma}, S. and
	{Krishnamurthy}, B.},
	title = "{MAGIX: Model Agnostic Globally Interpretable Explanations}",
	journal = {ArXiv e-prints},
	archivePrefix = "arXiv",
	eprint = {1706.07160},
	primaryClass = "cs.AI",
	keywords = {Computer Science - Artificial Intelligence},
	year = 2017,
	month = jun,
	adsurl = {http://adsabs.harvard.edu/abs/2017arXiv170607160P},
	adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

 @inbook{Zeiler_Fergus_2014, title={Visualizing and Understanding Convolutional Networks}, ISBN={978-3-319-10590-1}, abstractNote={Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark Krizhevsky et al. [18]. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we explore both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architectures that outperform Krizhevsky et al on the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.}, booktitle={Computer Vision – ECCV 2014}, publisher={Springer International Publishing}, author={Zeiler, Matthew D. and Fergus, Rob}, editor={Fleet, David and Pajdla, Tomas and Schiele, Bernt and Tuytelaars, TinneEditors}, year={2014}, pages={818–833}}
