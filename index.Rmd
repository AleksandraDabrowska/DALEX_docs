--- 
title: "DALEX: Descriptive mAchine Learning EXplanations"
author: "Przemysław Biecek"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
output: 
  tufte::tufte_html:
    split_by: chapter
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
github-repo: rstudio/bookdown-demo
description: "Do not trust a black-box model. Unless it explains itself."
--- 

# Motivation

*Machine Learning* is a vague name, there is some *learning* and some *machines*, but what the heck is going on? 

Actually I like the vagueness, because the interpretation of the name evolves over time as the discipline does.

* Few years ago I would extend this name as *machines are learning from human*. The supervised learning was were popular, humans were involved in data labelling and machines were tuned to predict these labels.
* Now we face very nice examples of *machines that are learning from other machines*. Self playing in nnets like AlphaGo Zero learns from themself in blazing speed. Still humans are involved in designing of the environment but labelling turns out to be very expensive so we are looking for ways to learn from partial labels, fuzzy labels, or no labels at all.
* I imagine that in close future *humans will learn from machines*. Well trained black-boxes may train us how to be a better in playing go, how to better in reading PET images, or how to be better in writing of books.

To make this future possible we need tools that extract useful information from black-box models. And as the human supervision over the learning is smaller over time, the black-box understanding is more important. 
DALEX is *the tool* for this.

## Why DALEX?

Key features of the DALEX

* set of various techniques for exploration of black-box models. Some of these techniques are more useful for understanding of predictions, some are more useful in understanding of structure. 
* consistent grammar across various techniques. DALEX is a wrapper over very good tools. Unfortunately these tolls share different logic fo model exploration. DALEX is a smooth wrapper for these tools.
* focus on the models comparison. One can learn a lot from single black-box model, but actually we can learn much more by contrasting models with different structures, like linear models vs. ensembles of trees. All explainers in DALEX by default support model comparisons on various levels.
* visual explanations based on `ggplot2` package. Elegant, customizable, consistent plots that reveal useful features by glance.

In this book we will focus on three primary usecases for DALEX explainers.

## To validate

 -> jakośc modelu
 -> identyfikacja outlierów

## To understand

 -> ważność zmiennych
 -> breakDown

## To improve

 -> pdp plots i inżynieria cech
 -> breakDown dla outlierów

-

Chapter \@(#architecture) presents the architecture of the DALEX package. 
Chapter \@(#modelUnderstanding) presents explainers that explore overall model performance, variable importance of feature effects.
Chapter \@(#predictionUnderstanding) presents explainers that explore feature attribution for single predictions of validation of the reliability of a model prediction. 


## Trivia

![](images/dalex01small.jpg)

[The Daleks](https://en.wikipedia.org/wiki/Dalek) are a fictional extraterrestrial race portrayed in the [Doctor Who](https://en.wikipedia.org/wiki/Doctor_Who) BBC series. Rather dim aliens, known to repeat the phrase *Explain!* very often.

```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown'
), 'packages.bib')
```


