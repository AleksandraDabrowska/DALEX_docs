# Conditional structure

The dimension of input $x$ for black box models is usually high (large $p$). But in many cases small number of variables play important role in the model OR there are some reasons to believe that variables work in an additive fashion/low-level interactions in the model.

In such cases one may be interesting in verification how the conditional response for a selected interesting variable/variables looks like. 

Methods presented below help to understand the conditional structure of a model.

## Partial Dependence Plot {#pdpchapter}

Partial Dependence Plots (see **pdp** package [@pdp]) for a black box $f(x; \theta)$ calculates the expected output given a selected variable.

$$
p_i(x_i) = E_{x_{-i}}[ f(x^i, x^{-i}; \theta) ]
$$

Of course this expectation cannot be calculated directly as we do not know fully the $f()$ neither the distribution of $x_{-i}$. This value is estimated by 

$$
\hat p_i(x_i) = \frac{1}{n} \sum_{j=1}^{n} f(x^i_j, x_j^{-i}, \hat \theta) 
$$


Let's see an example for the model `HR_rf_model`. Below we are using `pdp::partial` function to calculate pdp curve for variable `satisfaction_level`. Then the curve is plotted with `plotPartial` (based on `lattice`) or `autoplot` (based on `ggplot2`).

```{r, message=FALSE, warning=FALSE}
library("pdp")
library("randomForest")
library("breakDown")

HR_rf_model <- randomForest(left~., data = breakDown::HR_data, ntree = 100)

part <- partial(HR_rf_model, "satisfaction_level")

plotPartial(part)

library("ggplot2")
autoplot(part)
```

## Individual Conditional Expectation Plot

Individual Conditional Expectations (ICE) may be considered as an extension of the PDP curves (see **ICEbox** package [@ICEbox]).
Instead of plotting expected value over all observations, for ICE we are plotting individual conditional model responses. Average of ICE curves results in PDP curve.

An ICE curve for observation $k$ over variable $i$ may be defined as

$$
ice_k(x_i) = f(x^i, x_k^{-i}; \theta) 
$$

ICE curves can be plotted with `pdp` package. Note that curves may be cantered in a given point, this helps in identification of possible interactions.

```{r, message=FALSE, warning=FALSE}
library("pdp")
library("randomForest")
library("breakDown")
library("ggplot2")

HR_rf_model <- randomForest(left~., data = breakDown::HR_data, ntree = 100)

part_rf_satisfaction <- partial(HR_rf_model, "satisfaction_level")

part_rf_satisfaction <- partial(HR_rf_model, pred.var = "satisfaction_level", ice = TRUE)
plotPartial(part_rf_satisfaction, rug = TRUE, train = HR_data, alpha = 0.2)
autoplot(part_rf_satisfaction, center = TRUE, alpha = 0.2, rug = TRUE, train = HR_data)
```

Or with the `ICEbox` package.

```{r, message=FALSE, warning=FALSE}
library("ICEbox")
part_rf_satisfaction = ice(object = HR_rf_model, X = HR_data, y = HR_data$satisfaction_level, 
          predictor = "satisfaction_level", frac_to_build = .1)
plot(part_rf_satisfaction)
```

As ICE curves are useful tool for identification of interactions, these individual curves may be clustered with the `clusterICE` function.

```{r, message=FALSE, warning=FALSE}
clusterICE(part_rf_satisfaction, nClusters = 3, plot_legend = TRUE, center = TRUE)
```


## Accumulated Local Effects Plot

As it is presented in the chapter \@(pdpchapter), the Partial Dependence Plot presents the expected model response with respect to marginal distribution of $x_{-i}$. 
In some cases, e.g. when repressors are highly correlated, expectation over the marginal distribution may lead to biases/poorly extrapolated model responses. Especially in area far from the training set (see [@ALEPlot] for more details).

Accumulated local effects (ALE) plots (see **ALEPlot** package [@ALEPlot]) solves this problem by using conditional distribution $x_{-i}|x_i = x_i^*$. This leads to more stable and reliable estimates (at least when the predictors are highly correlated).

Let see an example for ALE plots.

```{r, message=FALSE, warning=FALSE}
library("ALEPlot")

HR_rf_model <- randomForest(left~., data = breakDown::HR_data, ntree = 100)

HR_data_small <- HR_data[,c("satisfaction_level", "last_evaluation", "number_project", 
"average_montly_hours", "time_spend_company", "Work_accident", "promotion_last_5years", "sales", "salary")]
```

Estimation of main effects for `satisfaction_level` is similar to the PDP curves

```{r, message=FALSE, warning=FALSE}
ale1d <- ALEPlot(X = HR_data_small, X.model = HR_rf_model, 
               pred.fun = function(X.model, newdata) {
                 predict(X.model, newdata)
               }, 
               J = 1)
```

And here we have predictions for `satisfaction_level` and `last_evaluation`.

```{r, message=FALSE, warning=FALSE}
ale2d <- ALEPlot(X = HR_data_small, X.model = HR_rf_model, 
               pred.fun = function(X.model, newdata) {
                 predict(X.model, newdata)
               }, 
               J = c(1,2))

```


## Mering Path Plot

The package `ICEbox` is not working for factor variables while the `pdp` package returns plots that are hard to interpret.

An interesting tool that helps to understand what is happening with factor variables is the **factorMerger** package (see [@factorMerger]).

Here we have Merging Path Plot for a factor variable `sales`.

```{r, message=FALSE, warning=FALSE, fig.width=12, fig.height=8}
library("factorMerger")
path <- mergeFactors(HR_data$left, HR_data$sales, method = "fast-adaptive", 
                     family = "binomial", abbreviate = FALSE)
plot(path, panel = "all")
```

Note that you can use the `factorMerger` package to understand predictions calculated with a black-box model. The random forest model `HR_rf_model` returns continuous response. But the `factorMerger` works for such variables as well.

In the top right panel one mey see the distribution of predictions for the selected group.

```{r, message=FALSE, warning=FALSE, fig.width=12, fig.height=8}

HR_data$left_predicted <- predict(HR_rf_model)

path <- mergeFactors(HR_data$left_predicted, HR_data$sales, method = "fast-adaptive", 
                     abbreviate = FALSE)
plot(path, panel = "all", responsePanel = "boxplot", nodesSpacing = "effects")
```


