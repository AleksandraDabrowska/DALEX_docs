# Model understanding  {#modelUnderstanding}

In this chapter we will introduce three groups of explainers that can be used to boost our understanding of a black-box models.

* Section \@ref(modelPerformance) presents explainers for model performance. Single number may be misleading when we need to compare complex models. Here you will find plots that give more information about model performance in a consistent form.
* Section \@ref(featureImportance) presents explainers for variable importance. Knowing which variables are important allow to validate the model and increase our understanding of the domain.
* Section \@ref(variableResponse) presents explainers for variable effect. Here you will find plots that summaries the relation between model response and particular variable.

All explainers are illustrated based on two models fitted to the `apartments` data.

```{r, warning=FALSE, message=FALSE}
library("DALEX")
apartments_lm_model <- lm(m2.price ~ construction.year + surface + floor + 
                      no.rooms + district, data = apartments)
library("randomForest")
set.seed(1313)
apartments_rf_model <- randomForest(m2.price ~ construction.year + surface + floor + 
                      no.rooms + district, data = apartments)
```

First we need to prepare wrappers for these models. They will be available in `explainer_lm` and `explainer_rf` objects.

```{r, warning=FALSE, message=FALSE}
explainer_lm <- explain(apartments_lm_model, 
                       data = apartmentsTest[,2:6], y = apartmentsTest$m2.price)
explainer_rf <- explain(apartments_rf_model, 
                       data = apartmentsTest[,2:6], y = apartmentsTest$m2.price)
```

## Model performance {#modelPerformance}

As you may remember from previous chapter [root mean square](https://en.wikipedia.org/wiki/Root_mean_square) of residuals is similar for both considered models. Does it mean that these models are equally good?

```{r, warning=FALSE, message=FALSE}
predicted_mi2_lm <- predict(apartments_lm_model, apartmentsTest)
sqrt(mean((predicted_mi2_lm - apartmentsTest$m2.price)^2))

predicted_mi2_rf <- predict(apartments_rf_model, apartmentsTest)
sqrt(mean((predicted_mi2_rf - apartmentsTest$m2.price)^2))
```

The function `model_performance()` calculates predictions for validation `data` and differences between model predictions and supplied labels `y`.

The generic `print()` function returns quantiles for these differences.

```{r}
mp_lm <- model_performance(explainer_lm)
mp_rf <- model_performance(explainer_rf)
mp_lm
mp_rf
```

The generic `plot()` function shows reversed empirical cumulative distribution function for absolute values from quintiles. This function presents fraction of residuals larger than `x`. The figure below shows that majority of residuals for random forest is smaller than residuals in linear model. But the small fraction of very large residuals affects the root mean square.

```{r global_explain_ecdf, fig.cap="Comparison of residuals for linear model and random forest"}
plot(mp_lm, mp_rf)
```

Use the `geom = "boxplot"` parameter for the generic `plot()` function to get alternative comparison of residuals. The red dot here stands for the root mean square.

```{r global_explain_boxplot, fig.height=2.5, fig.cap="Comparison of residuals for linear model and random forest"}
plot(mp_lm, mp_rf, geom = "boxplot")
```


## Feature importance {#featureImportance}

Explainers presented in this section are designed to better understand which variables are the most important? 

Some models, like linear regression or random forest have build-in *model specific* methods to calculate are visualize variable importance. They will be presented in Section \@ref(modelSpecific).

Section \@ref(modelAgnostic) presents a model agnostic approach based on permutations. The advantage of this approach is that different models can be compare within a single setup.


### Model agnostic {#modelAgnostic}

Model agnostic variable importance is calculated via permutations. Simply the loss function is compared between the full model and the model with single variable being permuted. The concept along with some extensions is described in [@variableImportancePermutations].

In DALEX this method is implemented in the `variable_importance()` function. Loss function is calculated for a model

* based on validation `data`, this is an estimate of model performance (will be denoted as `_full_model_`),
* based on a data with resampled labels `y`, this is kind of *worst case* loss when model are compares against random labels (will be denoted as `_baseline_`)
* based on a data with single variable being resampled, this will tell us how much model looses when selected variable is blinded.


Let's see how this function is working for a random forest model. 

```{r}
vi_rf <- variable_importance(explainer_rf, loss_function = loss_root_mean_square)
vi_rf
```

<p><span class="marginnote">Here the `loss_root_mean_square()` function is defined as square root from averaged squared differences between labels and model predictions.
</span>
Same method may be applied to linear model. Since we are using same loss function and same method for variable permutations then losses calculated with both methods can be directly compared.</p>


```{r}
vi_lm <- variable_importance(explainer_lm, loss_function = loss_root_mean_square)
vi_lm
```

It is much easier to compare both models when these values are plotted.
The generic `plot()` function may handle both models. 

```{r modelImportanceRaw, message=FALSE, warning=FALSE, fig.height=3.5, fig.cap="Model agnostic variable importance plot. Right edges correspond to loss function after permutation of a single variable. Left edges correspond to loss of a full model"}
plot(vi_lm, vi_rf)
```

What we can read out of this plot?

* left edges of intervals start in `_full_model_` losses, and as we see the performances are similar for both models
* length of the interval correspond to variable importance. In both models the most important variables are `district` and `surface`
* in the random forest model the `construction_year` variable has some importance while for linear model its importance is almost zero
* the variable `no.rooms` (which is correlated with `surface`) has some importance in the random forest model but not in the linear model.

We may be interested in variables that behave differently between models (like `construction_year`) or variables that are important (like `district` or `surface`). In the next section we will introduce explainers for further investigations.


*NOTE:* If you like to have all intervals hooked to 0, you can do this as well. Just add `type = "difference"` parameter to `variable_importance()`.

```{r modelImportanceDifference, message=FALSE, warning=FALSE, fig.height=3.5, fig.cap="Model agnostic variable importance plot. Right edges correspond to difference between loss after permutation of a single variable and loss of a full model"}
vi_lm <- variable_importance(explainer_lm, loss_function = loss_root_mean_square, type = "difference")
vi_rf <- variable_importance(explainer_rf, loss_function = loss_root_mean_square, type = "difference")
plot(vi_lm, vi_rf)
```


### Model specific {#modelSpecific}

Some models have build-in tools for calculation of variable importance.
Random forest is using two different measures, one based on out-of-bag data and second based on gains in nodes. Read more about this approach in [@randomForest]. 

Below we show an example of dot plot that summarizes default importance measure for random forest. The `varImpPlot()` function is available in the `randomForest` package.


```{r modelImportanceRF, message=FALSE, warning=FALSE, fig.height=3.5, fig.cap="Built-in variable importance plot for random forest"}
varImpPlot(apartments_rf_model)
```

It is also straightforward to assess variable importance for linear models and generalized models. It is simple since model coefficients have direct interpretation.

[Forest plots](https://en.wikipedia.org/wiki/Forest_plot) were initially used in the meta analysis to visualise effects in different studies. But now they are frequently used to present summary characteristics for models with linear structure like these created with `lm` or `glm` functions.

There are various implementations of forest plots in R. In the package **forestmodel** (see [@forestmodel]) one can use `forest_model()` function to draw a forest plot. This package is based on the **broom** package (see [@broom]) and this is why it handles a large variety of different regression models. 

```{r forestmodel, warning=FALSE, message=FALSE, fig.width=10, fig.width=5, fig.cap='Forest plot created with forestmodel package'}
library("forestmodel")
forest_model(apartments_lm_model)
```

In the package **sjPlot** (see [@sjPlot]) one can find `sjp.*()` function to visualise coefficients of a `*` model (like `sjp.glm()` for `glm` models) or a wrapper `plot_model()`. 


```{r sjpglm, message=FALSE, warning=FALSE, fig.width=10, fig.width=8, fig.cap='Model coefficients plotted  with sjPlot package'}
library("sjPlot")
plot_model(apartments_lm_model, type = "est", sort.est = TRUE)
```

**Note!** 

The **forestmodel** package handles factor variables in a better way while the plots from **sjPlot** are easier to read.


## Variable response {#variableResponse}

![Cheatsheet](images/DALEX_single_variable.png)

The dimension of input $x$ for black box models is usually high (large $p$). But in many cases small number of variables play important role in the model OR there are some reasons to believe that variables work in an additive fashion/low-level interactions in the model.

In such cases one may be interesting in verification how the conditional response for a selected interesting variable/variables looks like. 

Methods presented below help to understand the conditional structure of a model.

### Partial Dependence Plot {#pdpchapter}

Partial Dependence Plots (see **pdp** package [@pdp]) for a black box $f(x; \theta)$ calculates the expected output given a selected variable.

$$
p_i(x_i) = E_{x_{-i}}[ f(x^i, x^{-i}; \theta) ]
$$

Of course this expectation cannot be calculated directly as we do not know fully the $f()$ neither the distribution of $x_{-i}$. This value is estimated by 

$$
\hat p_i(x_i) = \frac{1}{n} \sum_{j=1}^{n} f(x^i_j, x_j^{-i}, \hat \theta) 
$$


Let's see an example for the model `HR_rf_model`. Below we are using `DALEX::single_variable` function that is calling   `pdp::partial` function to calculate pdp curve for variable `satisfaction_level`. Then the curve is plotted with generic `plot.single_variable_explainer()` function.

Marginal response plots are created in four steps.

1. We need to fit model. For example a Random Forest model.

```{r, message=FALSE, warning=FALSE}
library("randomForest")
library("breakDown")

HR_rf_model <- randomForest(left~., data = breakDown::HR_data, ntree = 100)
# a79f3c7ec27499fb91e46ee70d423ac8
# archivist::aread("pbiecek/DALEX/arepo/a79f3c7ec27")
```

2. We need to create an explainer. It's an interface that can be used to explain a black-box model.

```{r, message=FALSE, warning=FALSE}
library("DALEX")
explainer_rf  <- explain(HR_rf_model, data = HR_data)
```

3. Now we can calculate the marginal response with the PDP method.

```{r, message=FALSE, warning=FALSE}
expl_rf  <- single_variable(explainer_rf, variable =  "satisfaction_level", type = "pdp")
```

4. And we are ready to plot it.

```{r, message=FALSE, warning=FALSE}
plot(expl_rf)
# ad0f1699de646c78a46a3bf23aeea799
# archivist::aread("pbiecek/DALEX/arepo/ad0f1699")
```


### Model Comparisons

Marginal response plots are very useful in comparisons of different models. Let's fit Generalized Linear Model, Random Forest Model and XGBoost Model to the same data.

Then we can use PDP plots to compare these models. Random Forest Model was fitted in the previous chapter. Here we are training remaining models.

```{r, message=FALSE, warning=FALSE}
HR_glm_model <- glm(left~., data = breakDown::HR_data, family = "binomial")

library("xgboost")
model_martix_train <- model.matrix(left~.-1, breakDown::HR_data)
data_train <- xgb.DMatrix(model_martix_train, label = breakDown::HR_data$left)
param <- list(max_depth = 2, eta = 1, silent = 1, nthread = 2,
              objective = "binary:logistic", eval_metric = "auc")
HR_xgb_model <- xgb.train(param, data_train, nrounds = 50)
```

Models are trained. Now we can create explainers and single variable explanations

```{r}
logit <- function(x) exp(x)/(1+exp(x))

explainer_glm <- explain(HR_glm_model, data = HR_data)
expl_glm <- single_variable(explainer_glm, "satisfaction_level", "pdp", trans=logit)
```

In order to compare these models it's enough to plot all of them into a single chart.

```{r}
plot(expl_rf, expl_glm)
```

### Accumulated Local Effects Plot

As it is presented in the chapter \@(pdpchapter), the Partial Dependence Plot presents the expected model response with respect to marginal distribution of $x_{-i}$. 
In some cases, e.g. when repressors are highly correlated, expectation over the marginal distribution may lead to biases/poorly extrapolated model responses. Especially in area far from the training set (see [@ALEPlot] for more details).

Accumulated local effects (ALE) plots (see **ALEPlot** package [@ALEPlot]) solves this problem by using conditional distribution $x_{-i}|x_i = x_i^*$. This leads to more stable and reliable estimates (at least when the predictors are highly correlated).

Let see an example for ALE plots. We can used the model and explainer created in steps 1-2 in the PDP chapter above.

Estimation of main effects for `satisfaction_level` is similar to the PDP curves. Here we are using `DALEX::single_variable` function that is calling   `ALEPlot::ALEPlot` function to calculate ALE curve for variable `satisfaction_level`. 

```{r, message=FALSE, warning=FALSE}
exel_rf  <- single_variable(explainer_rf, variable = "satisfaction_level", type = "ale")

plot(exel_rf)
```

It may be useful to compare ALEPlots and PDP plots.
Again, it's simple with the generic DALEX function.

```{r, message=FALSE, warning=FALSE}
plot(expl_rf, exel_rf)
```

### Individual Conditional Expectation Plot

Individual Conditional Expectations (ICE) may be considered as an extension of the PDP curves (see **ICEbox** package [@ICEbox]).
Instead of plotting expected value over all observations, for ICE we are plotting individual conditional model responses. Average of ICE curves results in PDP curve.

An ICE curve for observation $k$ over variable $i$ may be defined as

$$
ice_k(x_i) = f(x^i, x_k^{-i}; \theta) 
$$

ICE curves can be plotted with `pdp` package. Note that curves may be cantered in a given point, this helps in identification of possible interactions.

```{r, message=FALSE, warning=FALSE}
library("pdp")
library("randomForest")
library("breakDown")
library("ggplot2")

HR_rf_model <- randomForest(left~., data = breakDown::HR_data, ntree = 100)

part_rf_satisfaction <- partial(HR_rf_model, "satisfaction_level")

part_rf_satisfaction <- partial(HR_rf_model, pred.var = "satisfaction_level", ice = TRUE)
plotPartial(part_rf_satisfaction, rug = TRUE, train = HR_data, alpha = 0.2)
autoplot(part_rf_satisfaction, center = TRUE, alpha = 0.2, rug = TRUE, train = HR_data)
```

Or with the `ICEbox` package.

```{r, message=FALSE, warning=FALSE}
library("ICEbox")
part_rf_satisfaction = ice(object = HR_rf_model, X = HR_data, y = HR_data$satisfaction_level, 
          predictor = "satisfaction_level", frac_to_build = .1)
plot(part_rf_satisfaction)
```

As ICE curves are useful tool for identification of interactions, these individual curves may be clustered with the `clusterICE` function.

```{r, message=FALSE, warning=FALSE}
clusterICE(part_rf_satisfaction, nClusters = 3, plot_legend = TRUE, center = TRUE)
```



### Mering Path Plot

The package `ICEbox` is not working for factor variables while the `pdp` package returns plots that are hard to interpret.

An interesting tool that helps to understand what is happening with factor variables is the **factorMerger** package (see [@factorMerger]).

Here we have Merging Path Plot for a factor variable `sales`.

```{r, message=FALSE, warning=FALSE, fig.width=12, fig.height=8}
library("factorMerger")
path <- mergeFactors(HR_data$left, HR_data$sales, method = "fast-adaptive", 
                     family = "binomial", abbreviate = FALSE)
plot(path, panel = "response") + theme_mi2()
```

Note that you can use the `factorMerger` package to understand predictions calculated with a black-box model. The random forest model `HR_rf_model` returns continuous response. But the `factorMerger` works for such variables as well.

In the top right panel one may see the distribution of predictions for the selected group.

```{r, message=FALSE, warning=FALSE, fig.width=12, fig.height=8}

HR_data$left_predicted <- predict(HR_rf_model)

path <- mergeFactors(HR_data$left_predicted, HR_data$sales, method = "fast-adaptive", 
                     abbreviate = FALSE)
plot(path, panel = "response", responsePanel = "boxplot", nodesSpacing = "effects") + theme_mi2()
```





