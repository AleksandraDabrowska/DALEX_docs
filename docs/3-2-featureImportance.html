<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta property="og:title" content="DALEX: Descriptive mAchine Learning EXplanations" />
<meta property="og:type" content="book" />


<meta property="og:description" content="Do not trust a black-box model. Unless it explains itself." />
<meta name="github-repo" content="rstudio/bookdown-demo" />

<meta name="author" content="Przemysław Biecek" />

<meta name="date" content="2018-04-02" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="Do not trust a black-box model. Unless it explains itself.">

<title>DALEX: Descriptive mAchine Learning EXplanations</title>

<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="toc.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li class="has-sub"><a href="index.html#introduction"><span class="toc-section-number">1</span> Introduction</a><ul>
<li class="has-sub"><a href="1-1-motivation.html#motivation"><span class="toc-section-number">1.1</span> Motivation</a><ul>
<li><a href="1-1-motivation.html#why-dalex"><span class="toc-section-number">1.1.1</span> Why DALEX?</a></li>
<li><a href="1-1-motivation.html#to-validate"><span class="toc-section-number">1.1.2</span> To validate</a></li>
<li><a href="1-1-motivation.html#to-understand"><span class="toc-section-number">1.1.3</span> To understand</a></li>
<li><a href="1-1-motivation.html#to-improve"><span class="toc-section-number">1.1.4</span> To improve</a></li>
</ul></li>
<li><a href="1-2-trivia.html#trivia"><span class="toc-section-number">1.2</span> Trivia</a></li>
</ul></li>
<li class="has-sub"><a href="2-architecture.html#architecture"><span class="toc-section-number">2</span> Architecture of DALEX</a><ul>
<li><a href="2-1-explainFunction.html#explainFunction"><span class="toc-section-number">2.1</span> The <code>explain()</code> function</a></li>
<li class="has-sub"><a href="2-2-use-case-regression-apartment-prices-in-warsaw.html#use-case-regression.-apartment-prices-in-warsaw"><span class="toc-section-number">2.2</span> Use case: Regression. Apartment prices in Warsaw</a><ul>
<li><a href="2-2-use-case-regression-apartment-prices-in-warsaw.html#linear-regression"><span class="toc-section-number">2.2.1</span> Linear regression</a></li>
<li><a href="2-2-use-case-regression-apartment-prices-in-warsaw.html#random-forest"><span class="toc-section-number">2.2.2</span> Random forest</a></li>
</ul></li>
<li><a href="2-3-use-case-classification-tbd.html#use-case-classification.-tbd"><span class="toc-section-number">2.3</span> Use case: Classification. TBD</a></li>
</ul></li>
<li class="has-sub"><a href="3-modelUnderstanding.html#modelUnderstanding"><span class="toc-section-number">3</span> Model understanding</a><ul>
<li><a href="3-1-modelPerformance.html#modelPerformance"><span class="toc-section-number">3.1</span> Model performance</a></li>
<li class="has-sub"><a href="3-2-featureImportance.html#featureImportance"><span class="toc-section-number">3.2</span> Feature importance</a><ul>
<li><a href="3-2-featureImportance.html#modelAgnostic"><span class="toc-section-number">3.2.1</span> Model agnostic</a></li>
<li><a href="3-2-featureImportance.html#modelSpecific"><span class="toc-section-number">3.2.2</span> Model specific</a></li>
</ul></li>
<li class="has-sub"><a href="3-3-variableResponse.html#variableResponse"><span class="toc-section-number">3.3</span> Variable response</a><ul>
<li><a href="3-3-variableResponse.html#pdpchapter"><span class="toc-section-number">3.3.1</span> Partial Dependence Plot</a></li>
<li><a href="3-3-variableResponse.html#model-comparisons"><span class="toc-section-number">3.3.2</span> Model Comparisons</a></li>
<li><a href="3-3-variableResponse.html#accumulated-local-effects-plot"><span class="toc-section-number">3.3.3</span> Accumulated Local Effects Plot</a></li>
<li><a href="3-3-variableResponse.html#individual-conditional-expectation-plot"><span class="toc-section-number">3.3.4</span> Individual Conditional Expectation Plot</a></li>
<li><a href="3-3-variableResponse.html#mering-path-plot"><span class="toc-section-number">3.3.5</span> Mering Path Plot</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="4-predictionUnderstanding.html#predictionUnderstanding"><span class="toc-section-number">4</span> Prediction understanding</a><ul>
<li><a href="4-1-outlier-detection.html#outlier-detection"><span class="toc-section-number">4.1</span> Outlier detection</a></li>
<li class="has-sub"><a href="4-2-predictionBreakdown.html#predictionBreakdown"><span class="toc-section-number">4.2</span> Prediction breakdown</a><ul>
<li><a href="4-2-predictionBreakdown.html#basics"><span class="toc-section-number">4.2.1</span> Basics</a></li>
</ul></li>
<li><a href="4-3-local-interpretable-model-agnostic-visual-explanations.html#local-interpretable-model-agnostic-visual-explanations"><span class="toc-section-number">4.3</span> Local Interpretable (Model-agnostic) Visual Explanations</a></li>
<li class="has-sub"><a href="4-4-breakdown.html#breakdown"><span class="toc-section-number">4.4</span> breakDown</a><ul>
<li><a href="4-4-breakdown.html#model-comparisons-1"><span class="toc-section-number">4.4.1</span> Model Comparisons</a></li>
</ul></li>
</ul></li>
<li><a href="5-reproducibility.html#reproducibility"><span class="toc-section-number">5</span> Reproducibility</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="featureImportance" class="section level2">
<h2><span class="header-section-number">3.2</span> Feature importance</h2>
<p>Explainers presented in this section are designed to better understand which variables are the most important?</p>
<p>Some models, like linear regression or random forest have build-in <em>model specific</em> methods to calculate are visualize variable importance. They will be presented in Section <a href="3-2-featureImportance.html#modelSpecific">3.2.2</a>.</p>
<p>Section <a href="3-2-featureImportance.html#modelAgnostic">3.2.1</a> presents a model agnostic approach based on permutations. The advantage of this approach is that different models can be compare within a single setup.</p>
<div id="modelAgnostic" class="section level3">
<h3><span class="header-section-number">3.2.1</span> Model agnostic</h3>
<p>Model agnostic variable importance is calculated via permutations. Simply the loss function is compared between the full model and the model with single variable being permuted. The concept along with some extensions is described in <span class="citation">(Fisher, Rudin, and Dominici <label for="tufte-mn-14" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-14" class="margin-toggle">2018<span class="marginnote">Fisher, Aaron, Cynthia Rudin, and Francesca Dominici. 2018. “Model Class Reliance: Variable Importance Measures for Any Machine Learning Model Class, from the ’Rashomon’ Perspective.” <em>Journal of Computational and Graphical Statistics</em>. <a href="http://arxiv.org/abs/1801.01489" class="uri">http://arxiv.org/abs/1801.01489</a>.</span>)</span>.</p>
<p>In DALEX this method is implemented in the <code>variable_importance()</code> function. Loss function is calculated for a model</p>
<ul>
<li>based on validation <code>data</code>, this is an estimate of model performance (will be denoted as <code>_full_model_</code>),</li>
<li>based on a data with resampled labels <code>y</code>, this is kind of <em>worst case</em> loss when model are compares against random labels (will be denoted as <code>_baseline_</code>)</li>
<li>based on a data with single variable being resampled, this will tell us how much model looses when selected variable is blinded.</li>
</ul>
<p>Let’s see how this function is working for a random forest model.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb24-1" data-line-number="1">vi_rf &lt;-<span class="st"> </span><span class="kw">variable_importance</span>(explainer_rf, <span class="dt">loss_function =</span> loss_root_mean_square)</a>
<a class="sourceLine" id="cb24-2" data-line-number="2">vi_rf</a></code></pre></div>
<pre><code>##            variable dropout_loss        label
## 1      _full_model_     276.5710 randomForest
## 2          no.rooms     392.7976 randomForest
## 3 construction.year     396.4986 randomForest
## 4             floor     447.9885 randomForest
## 5           surface     468.9430 randomForest
## 6          district     825.4795 randomForest
## 7        _baseline_    1105.0129 randomForest</code></pre>
<p>
<span class="marginnote">Here the <code>loss_root_mean_square()</code> function is defined as square root from averaged squared differences between labels and model predictions. </span> Same method may be applied to linear model. Since we are using same loss function and same method for variable permutations then losses calculated with both methods can be directly compared.
</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb26-1" data-line-number="1">vi_lm &lt;-<span class="st"> </span><span class="kw">variable_importance</span>(explainer_lm, <span class="dt">loss_function =</span> loss_root_mean_square)</a>
<a class="sourceLine" id="cb26-2" data-line-number="2">vi_lm</a></code></pre></div>
<pre><code>##            variable dropout_loss label
## 1      _full_model_     287.9370    lm
## 2 construction.year     287.9141    lm
## 3          no.rooms     303.5316    lm
## 4             floor     495.2068    lm
## 5           surface     650.4580    lm
## 6          district    1045.1731    lm
## 7        _baseline_    1298.8958    lm</code></pre>
<p>It is much easier to compare both models when these values are plotted. The generic <code>plot()</code> function may handle both models.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb28-1" data-line-number="1"><span class="kw">plot</span>(vi_lm, vi_rf)</a></code></pre></div>
<div class="figure"><span id="fig:modelImportanceRaw"></span>
<p class="caption marginnote shownote">
Figure 3.1: Model agnostic variable importance plot. Right edges correspond to loss function after permutation of a single variable. Left edges correspond to loss of a full model
</p>
<img src="DALEX_files/figure-html/modelImportanceRaw-1.png" alt="Model agnostic variable importance plot. Right edges correspond to loss function after permutation of a single variable. Left edges correspond to loss of a full model" width="672"  />
</div>
<p>What we can read out of this plot?</p>
<ul>
<li>left edges of intervals start in <code>_full_model_</code> losses, and as we see the performances are similar for both models</li>
<li>length of the interval correspond to variable importance. In both models the most important variables are <code>district</code> and <code>surface</code></li>
<li>in the random forest model the <code>construction_year</code> variable has some importance while for linear model its importance is almost zero</li>
<li>the variable <code>no.rooms</code> (which is correlated with <code>surface</code>) has some importance in the random forest model but not in the linear model.</li>
</ul>
<p>We may be interested in variables that behave differently between models (like <code>construction_year</code>) or variables that are important (like <code>district</code> or <code>surface</code>). In the next section we will introduce explainers for further investigations.</p>
<p><em>NOTE:</em> If you like to have all intervals hooked to 0, you can do this as well. Just add <code>type = &quot;difference&quot;</code> parameter to <code>variable_importance()</code>.</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb29-1" data-line-number="1">vi_lm &lt;-<span class="st"> </span><span class="kw">variable_importance</span>(explainer_lm, <span class="dt">loss_function =</span> loss_root_mean_square, <span class="dt">type =</span> <span class="st">&quot;difference&quot;</span>)</a>
<a class="sourceLine" id="cb29-2" data-line-number="2">vi_rf &lt;-<span class="st"> </span><span class="kw">variable_importance</span>(explainer_rf, <span class="dt">loss_function =</span> loss_root_mean_square, <span class="dt">type =</span> <span class="st">&quot;difference&quot;</span>)</a>
<a class="sourceLine" id="cb29-3" data-line-number="3"><span class="kw">plot</span>(vi_lm, vi_rf)</a></code></pre></div>
<div class="figure"><span id="fig:modelImportanceDifference"></span>
<p class="caption marginnote shownote">
Figure 3.2: Model agnostic variable importance plot. Right edges correspond to difference between loss after permutation of a single variable and loss of a full model
</p>
<img src="DALEX_files/figure-html/modelImportanceDifference-1.png" alt="Model agnostic variable importance plot. Right edges correspond to difference between loss after permutation of a single variable and loss of a full model" width="672"  />
</div>
</div>
<div id="modelSpecific" class="section level3">
<h3><span class="header-section-number">3.2.2</span> Model specific</h3>
<p>Some models have build-in tools for calculation of variable importance. Random forest is using two different measures, one based on out-of-bag data and second based on gains in nodes. Read more about this approach in <span class="citation">(Liaw and Wiener <label for="tufte-mn-15" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-15" class="margin-toggle">2002<span class="marginnote">Liaw, Andy, and Matthew Wiener. 2002. “Classification and Regression by randomForest.” <em>R News</em> 2 (3):18–22. <a href="http://CRAN.R-project.org/doc/Rnews/" class="uri">http://CRAN.R-project.org/doc/Rnews/</a>.</span>)</span>.</p>
<p>Below we show an example of dot plot that summarizes default importance measure for random forest. The <code>varImpPlot()</code> function is available in the <code>randomForest</code> package.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb30-1" data-line-number="1"><span class="kw">varImpPlot</span>(apartments_rf_model)</a></code></pre></div>
<div class="figure"><span id="fig:modelImportanceRF"></span>
<p class="caption marginnote shownote">
Figure 3.3: Built-in variable importance plot for random forest
</p>
<img src="DALEX_files/figure-html/modelImportanceRF-1.png" alt="Built-in variable importance plot for random forest" width="672"  />
</div>
<p>It is also straightforward to assess variable importance for linear models and generalized models. It is simple since model coefficients have direct interpretation.</p>
<p><a href="https://en.wikipedia.org/wiki/Forest_plot">Forest plots</a> were initially used in the meta analysis to visualise effects in different studies. But now they are frequently used to present summary characteristics for models with linear structure like these created with <code>lm</code> or <code>glm</code> functions.</p>
<p>There are various implementations of forest plots in R. In the package <strong>forestmodel</strong> (see <span class="citation">(Kennedy <label for="tufte-mn-16" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-16" class="margin-toggle">2017<span class="marginnote">Kennedy, Nick. 2017. <em>Forestmodel: Forest Plots from Regression Models</em>. <a href="https://CRAN.R-project.org/package=forestmodel" class="uri">https://CRAN.R-project.org/package=forestmodel</a>.</span>)</span>) one can use <code>forest_model()</code> function to draw a forest plot. This package is based on the <strong>broom</strong> package (see <span class="citation">(Robinson <label for="tufte-mn-17" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-17" class="margin-toggle">2017<span class="marginnote">Robinson, David. 2017. <em>Broom: Convert Statistical Analysis Objects into Tidy Data Frames</em>. <a href="https://CRAN.R-project.org/package=broom" class="uri">https://CRAN.R-project.org/package=broom</a>.</span>)</span>) and this is why it handles a large variety of different regression models.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb31-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;forestmodel&quot;</span>)</a>
<a class="sourceLine" id="cb31-2" data-line-number="2"><span class="kw">forest_model</span>(apartments_lm_model)</a></code></pre></div>
<div class="figure"><span id="fig:forestmodel"></span>
<p class="caption marginnote shownote">
Figure 3.4: Forest plot created with forestmodel package
</p>
<img src="DALEX_files/figure-html/forestmodel-1.png" alt="Forest plot created with forestmodel package" width="480"  />
</div>
<p>In the package <strong>sjPlot</strong> (see <span class="citation">(Lüdecke <label for="tufte-mn-18" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-18" class="margin-toggle">2017<span class="marginnote">Lüdecke, Daniel. 2017. <em>SjPlot: Data Visualization for Statistics in Social Science</em>. <a href="https://CRAN.R-project.org/package=sjPlot" class="uri">https://CRAN.R-project.org/package=sjPlot</a>.</span>)</span>) one can find <code>sjp.*()</code> function to visualise coefficients of a <code>*</code> model (like <code>sjp.glm()</code> for <code>glm</code> models) or a wrapper <code>plot_model()</code>.</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb32-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;sjPlot&quot;</span>)</a>
<a class="sourceLine" id="cb32-2" data-line-number="2"><span class="kw">plot_model</span>(apartments_lm_model, <span class="dt">type =</span> <span class="st">&quot;est&quot;</span>, <span class="dt">sort.est =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<div class="figure"><span id="fig:sjpglm"></span>
<p class="caption marginnote shownote">
Figure 3.5: Model coefficients plotted with sjPlot package
</p>
<img src="DALEX_files/figure-html/sjpglm-1.png" alt="Model coefficients plotted  with sjPlot package" width="768"  />
</div>
<p><strong>Note!</strong></p>
<p>The <strong>forestmodel</strong> package handles factor variables in a better way while the plots from <strong>sjPlot</strong> are easier to read.</p>
</div>
</div>
<p style="text-align: center;">
<a href="3-1-modelPerformance.html"><button class="btn btn-default">Previous</button></a>
<a href="https://github.com/pbiecek/DALEX/edit/master/02-global.Rmd"><button class="btn btn-default">Edit</button></a>
<a href="3-3-variableResponse.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>



</body>
</html>
