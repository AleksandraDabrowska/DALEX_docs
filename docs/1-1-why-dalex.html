<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta property="og:title" content="DALEX: Descriptive mAchine Learning EXplanations" />
<meta property="og:type" content="book" />


<meta property="og:description" content="Do not trust a black-box model. Unless it explains itself." />
<meta name="github-repo" content="rstudio/bookdown-demo" />

<meta name="author" content="Przemysław Biecek" />

<meta name="date" content="2018-03-29" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="Do not trust a black-box model. Unless it explains itself.">

<title>DALEX: Descriptive mAchine Learning EXplanations</title>

<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="toc.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li class="has-sub"><a href="index.html#motivation"><span class="toc-section-number">1</span> Motivation</a><ul>
<li class="has-sub"><a href="1-1-why-dalex.html#why-dalex"><span class="toc-section-number">1.1</span> Why DALEX?</a><ul>
<li><a href="1-1-why-dalex.html#to-validate"><span class="toc-section-number">1.1.1</span> To validate</a></li>
<li><a href="1-1-why-dalex.html#to-understand"><span class="toc-section-number">1.1.2</span> To understand</a></li>
<li><a href="1-1-why-dalex.html#to-improve"><span class="toc-section-number">1.1.3</span> To improve</a></li>
</ul></li>
<li><a href="1-2-trivia.html#trivia"><span class="toc-section-number">1.2</span> Trivia</a></li>
</ul></li>
<li class="has-sub"><a href="2-architecture.html#architecture"><span class="toc-section-number">2</span> DALEX architecture</a><ul>
<li><a href="2-1-notation.html#notation"><span class="toc-section-number">2.1</span> Notation</a></li>
<li class="has-sub"><a href="2-2-use-case-human-resources-analytics.html#use-case---human-resources-analytics"><span class="toc-section-number">2.2</span> Use case - Human Resources Analytics</a><ul>
<li><a href="2-2-use-case-human-resources-analytics.html#logistic-regression"><span class="toc-section-number">2.2.1</span> Logistic regression</a></li>
<li><a href="2-2-use-case-human-resources-analytics.html#random-forest"><span class="toc-section-number">2.2.2</span> Random forest</a></li>
</ul></li>
<li class="has-sub"><a href="2-3-use-case-wine-quality.html#use-case---wine-quality"><span class="toc-section-number">2.3</span> Use case - Wine quality</a><ul>
<li><a href="2-3-use-case-wine-quality.html#linear-regression"><span class="toc-section-number">2.3.1</span> Linear regression</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="3-modelUnderstanding.html#modelUnderstanding"><span class="toc-section-number">3</span> Model understanding</a><ul>
<li><a href="3-1-modelPerformance.html#modelPerformance"><span class="toc-section-number">3.1</span> Model performance</a></li>
<li class="has-sub"><a href="3-2-featureImportance.html#featureImportance"><span class="toc-section-number">3.2</span> Feature importance</a><ul>
<li><a href="3-2-featureImportance.html#drop-out-plots"><span class="toc-section-number">3.2.1</span> Drop-out plots</a></li>
<li><a href="3-2-featureImportance.html#forest-plots"><span class="toc-section-number">3.2.2</span> Forest plots</a></li>
</ul></li>
<li class="has-sub"><a href="3-3-variableResponse.html#variableResponse"><span class="toc-section-number">3.3</span> Variable response</a><ul>
<li><a href="3-3-variableResponse.html#pdpchapter"><span class="toc-section-number">3.3.1</span> Partial Dependence Plot</a></li>
<li><a href="3-3-variableResponse.html#model-comparisons"><span class="toc-section-number">3.3.2</span> Model Comparisons</a></li>
<li><a href="3-3-variableResponse.html#accumulated-local-effects-plot"><span class="toc-section-number">3.3.3</span> Accumulated Local Effects Plot</a></li>
<li><a href="3-3-variableResponse.html#individual-conditional-expectation-plot"><span class="toc-section-number">3.3.4</span> Individual Conditional Expectation Plot</a></li>
<li><a href="3-3-variableResponse.html#mering-path-plot"><span class="toc-section-number">3.3.5</span> Mering Path Plot</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="4-predictionUnderstanding.html#predictionUnderstanding"><span class="toc-section-number">4</span> Prediction understanding</a><ul>
<li><a href="4-1-outlier-detection.html#outlier-detection"><span class="toc-section-number">4.1</span> Outlier detection</a></li>
<li class="has-sub"><a href="4-2-predictionBreakdown.html#predictionBreakdown"><span class="toc-section-number">4.2</span> Prediction breakdown</a><ul>
<li><a href="4-2-predictionBreakdown.html#basics"><span class="toc-section-number">4.2.1</span> Basics</a></li>
</ul></li>
<li><a href="4-3-local-interpretable-model-agnostic-visual-explanations.html#local-interpretable-model-agnostic-visual-explanations"><span class="toc-section-number">4.3</span> Local Interpretable (Model-agnostic) Visual Explanations</a></li>
<li class="has-sub"><a href="4-4-breakdown.html#breakdown"><span class="toc-section-number">4.4</span> breakDown</a><ul>
<li><a href="4-4-breakdown.html#model-comparisons-1"><span class="toc-section-number">4.4.1</span> Model Comparisons</a></li>
</ul></li>
</ul></li>
<li><a href="5-reproducibility.html#reproducibility"><span class="toc-section-number">5</span> Reproducibility</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="why-dalex" class="section level2">
<h2><span class="header-section-number">1.1</span> Why DALEX?</h2>
<p>There is a number of R packages that may be used for knowledge extraction from machine learning models. Like <code>pdp</code> <span class="citation">(Greenwell <label for="tufte-mn-2" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-2" class="margin-toggle">2017<span class="marginnote">Greenwell, Brandon M. 2017. “Pdp: An R Package for Constructing Partial Dependence Plots.” <em>The R Journal</em> 9 (1):421–36. <a href="https://journal.r-project.org/archive/2017/RJ-2017-016/index.html" class="uri">https://journal.r-project.org/archive/2017/RJ-2017-016/index.html</a>.</span>)</span>, <code>ALEPlot</code> <span class="citation">(Apley <label for="tufte-mn-3" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-3" class="margin-toggle">2017<span class="marginnote">Apley, Dan. 2017. <em>ALEPlot: Accumulated Local Effects (Ale) Plots and Partial Dependence (Pd) Plots</em>. <a href="https://CRAN.R-project.org/package=ALEPlot" class="uri">https://CRAN.R-project.org/package=ALEPlot</a>.</span>)</span>, <code>randomForestExplainer</code> <span class="citation">(Paluszynska and Biecek <label for="tufte-mn-4" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-4" class="margin-toggle">2017<span class="marginnote">Paluszynska, Aleksandra, and Przemyslaw Biecek. 2017. <em>RandomForestExplainer: A Set of Tools to Understand What Is Happening Inside a Random Forest</em>. <a href="https://github.com/MI2DataLab/randomForestExplainer" class="uri">https://github.com/MI2DataLab/randomForestExplainer</a>.</span>)</span>, <code>xgboostExplainer</code> <span class="citation">(Foster <label for="tufte-mn-5" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-5" class="margin-toggle">2017<span class="marginnote">Foster, David. 2017. <em>XgboostExplainer: An R Package That Makes Xgboost Models Fully Interpretable</em>. <a href="https://github.com/AppliedDataSciencePartners/xgboostExplainer/" class="uri">https://github.com/AppliedDataSciencePartners/xgboostExplainer/</a>.</span>)</span>, <code>live</code> <span class="citation">(Staniak and Biecek <label for="tufte-mn-6" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-6" class="margin-toggle">2017<span class="marginnote">Staniak, Mateusz, and Przemyslaw Biecek. 2017. <em>Live: Local Interpretable (Model-Agnostic) Visual Explanations</em>. <a href="https://github.com/MI2DataLab/live" class="uri">https://github.com/MI2DataLab/live</a>.</span>)</span> and others.</p>
<p>So why do we need yet another R package for this? There are some unique features of the DALEX package.</p>
<ul>
<li>Scope. DALEX is a wrapper over large number of very good tools / model explainers. It offers a wide range of state of the art techniques for model exploration. Some of these techniques are more useful for understanding of model predictions, some are more useful in understanding of structure.</li>
<li>Consistency. DALEX offers a consistent grammar across various techniques for model explanation. It’s a wrapper that smooths differences across different dependent packages.</li>
<li>Model agnostic. DALEX explainers are model agnostic, we can use them for linear models, tree ensembles of other structures. So we are not limited to any particular family of black-box models.</li>
<li>Model comparisons. One can learn a lot from single black-box model, but actually we can learn much more by contrasting models with different structures, like linear models vs. ensembles of trees. All explainers in DALEX by default support model comparisons on various levels.</li>
<li>Visual consistency. Each DALEX explainer can be plotted with the generic <code>plot()</code> function. These visual explanations are based on <code>ggplot2</code> <span class="citation">(Wickham <label for="tufte-mn-7" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-7" class="margin-toggle">2009<span class="marginnote">Wickham, Hadley. 2009. <em>Ggplot2: Elegant Graphics for Data Analysis</em>. Springer-Verlag New York. <a href="http://ggplot2.org" class="uri">http://ggplot2.org</a>.</span>)</span> package, which results in elegant, customizable, consistent graphs.</li>
</ul>
<p>Chapter <a href="2-architecture.html#architecture">2</a> presents the overall architecture of the DALEX package. Chapter <a href="3-modelUnderstanding.html#modelUnderstanding">3</a> presents explainers that explore global model performance, variable importance of feature effects. Chapter <a href="4-predictionUnderstanding.html#predictionUnderstanding"><strong>??</strong></a> presents explainers that explore feature attribution for single predictions of validation of the reliability of a model prediction.</p>
<p>In this document we will focus on three primary use-cases for DALEX explainers.</p>
<div id="to-validate" class="section level3">
<h3><span class="header-section-number">1.1.1</span> To validate</h3>
<p>Explainers presented in the section <a href="3-1-modelPerformance.html#modelPerformance">3.1</a> helps to understand model performance and compare different models on the same scale. The model comparison is richer that a one based on a single number and helps to understand model performance along the full range of model predictions.</p>
<p>Explainers presented in the section <a href="#outlierDetection"><strong>??</strong></a> helps to identify outliers or observations with particularly unusual value.</p>
<p>Explainers presented in the section <a href="4-2-predictionBreakdown.html#predictionBreakdown">4.2</a> helps to understand which features influence heavily model predictions.</p>
</div>
<div id="to-understand" class="section level3">
<h3><span class="header-section-number">1.1.2</span> To understand</h3>
<p>Explainers presented in the section <a href="3-2-featureImportance.html#featureImportance">3.2</a> helps to understand which variables are the most important in the model. Explainers presented in the section <a href="4-2-predictionBreakdown.html#predictionBreakdown">4.2</a> helps to understand which features influence single model predictions. They are useful to understand the key ingredients of the model.</p>
<p>Explainers presented in the section <a href="3-3-variableResponse.html#variableResponse">3.3</a> helps to understand how features affect model prediction.</p>
</div>
<div id="to-improve" class="section level3">
<h3><span class="header-section-number">1.1.3</span> To improve</h3>
<p>Explainers presented in the section <a href="3-3-variableResponse.html#variableResponse">3.3</a> helps to perform feature engineering based on feature marginal responses.</p>
<p>Explainers presented in the section <a href="4-2-predictionBreakdown.html#predictionBreakdown">4.2</a> helps to understand which variables affect incorrect model decisions. This is useful to identify and correct biases in the training data.</p>
</div>
</div>
<p style="text-align: center;">
<a href="index.html"><button class="btn btn-default">Previous</button></a>
<a href="https://github.com/pbiecek/DALEX/edit/master/index.Rmd"><button class="btn btn-default">Edit</button></a>
<a href="1-2-trivia.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>



</body>
</html>
