---
title: "eRum exercises"
author: "Mateusz Staniak"
output: pdf_document
---

## Exercises 

### Exercise 1

Run the following code to fit random forest, linear regression and SVM to the housing prices data.

```{r models, warning = F, message = F}
library(tidyverse)
library(live)
library(DALEX)
library(randomForest)
library(e1071)
library(auditor)
load("./rda_files/houses.rda")

set.seed(33)
house_rf <- randomForest(sqm_price ~., data = houses)
house_svm <- svm(sqm_price ~., data = houses)
house_lm <- lm(sqm_price ~., data = houses)
```

Create DALEX explainer object for each of the models. 
Create and compare boxplots of residuals for all the models (`model_performance`). 

  * Which model is the best?
  * Are there any outlying predictions?
  * Find the observation with the largest absolute value of residual among houses cheaper than 7000 PLN. 

TIP: object returned by `model_performance` function is a data frame with colnames 
_predicted_, _observed_, _diff_ and _label_.


### Exercise 2

Create single prediction explainers for the instance chosen in **Exercise 1**.
Create Break Down plots for each of the observations. What are the keys factors that drive the prediction?
Are they the same for every model?


### Exercise 3

Run the following code to train model random forest model using `mlr` interface 
(this is necessary for `shapleyR` package).

```{r ex51, message = F, warning = F}
library(mlr)
load("./rda_files/houses.rda")
n_obs <- 1189

house_task <- makeRegrTask(data = houses, target = "sqm_price")
house_rf_mlr <- train("regr.randomForest", house_task)
```

Use shapleyR package to calculate Shapley values for prediction chosen in **Exercise 1** (its index is in `n_obs` object). 
Are the results consistent with Break Down results from **Exercise 2**?
Draw a plot of Shapley values.

TIP: remember to set class of the object returned by `shapley` function to `shapley.singleValue` before using `plot`.


## Bonus 1:

Draw plots of fitted vs observed values for each of these models. Can you spot any problems with the predictions? Are the prices usually underestimated of overestimated?


### Bonus 2:

Create variable importance explainer. Compare global variable importance to scores obtained in **Exercise 2** and **Exercise 3**.


### Exercise 4

```{r ex3}
n_obs <- 1189
```

Simulate new data around the observation from **Exercise 1** (its index is in the `n_obs` object.) and the add random forest predictions.
Then fit a linear model locally.

TIP: remember to load `mlr` package.
TIP2: don't use too small `size` for the simulated dataset. I recommend at least 1000.


### Exercise 5

Visualize approximation created in **Exercise 4**.
Use `plot_explanation2` function to create a forest plot of the linear model and then the Break Down plot. 


### Exercise 6

Use `lime` package to approximate random forest model around prediction chosen in  **Exercise 1** (its index is in `n_obs` object).
Follow the `lime` work flow: 
  1. Create an explainer.
  2. Approximate the model around the explained instane.
  3. Use `plot_features` function to see, how features influence this prediction.


TIP: use `house_rf_mlr` object from **Exercise 5**, because `lime` works well with `mlr` objects.

### Bonus 3

Use `add_predictions` function to add SVM and LM predictions to the simulated dataset. Compare plots for all three models.


### Bonus 4

Run the following code to see largest residuals for _Psie Pole_ district.

```{r boncode}
library(tidyverse)
houses %>%
  mutate(id = 1:n()) %>%
  mutate(rf_pred = predict(house_rf)) %>%
  mutate(abs_res = abs(sqm_price - rf_pred)) %>%
  arrange(desc(abs_res)) %>%
  filter(sqm_price < 7000,
         district == "Psie Pole") %>%
  head(5)

n_obs2 <- 5830
```

Using `live` package, fit a linear model around the top observation.
Compare waterfall plots for this prediction and the prediction from **Exercise 5**.
How are they different?


## Solutions

### Exercise 1

```{r sol1}
rf_expl <- DALEX::explain(house_rf, data = houses, y = houses$sqm_price)
svm_expl <- DALEX::explain(house_svm, data = houses, y = houses$sqm_price)
lm_expl <- DALEX::explain(house_lm, data = houses, y = houses$sqm_price)

rf_perf <- model_performance(rf_expl)
svm_perf <- model_performance(svm_expl)
lm_perf <- model_performance(lm_expl)

plot(rf_perf, 
     svm_perf,
     lm_perf,
     geom = "boxplot")

rf_perf %>%
  mutate(id = 1:n()) %>%
  arrange(desc(abs(diff))) %>%
  filter(observed < 7000) %>%
  head(5)
svm_perf %>%
  mutate(id = 1:n()) %>%
  arrange(desc(abs(diff))) %>%
  filter(observed < 7000) %>%
  head(5)
lm_perf %>%
  mutate(id = 1:n()) %>%
  arrange(desc(abs(diff))) %>%
  filter(observed < 7000) %>%
  head(5)

n_obs <- which(houses$sqm_price == 1585)
```

### Exercise 2

```{r sol2}
rf_expl_sp <- single_prediction(rf_expl, houses[n_obs, -3])
svm_expl_sp <- single_prediction(svm_expl, houses[n_obs, -3])
lm_expl_sp  <-single_prediction(lm_expl, houses[n_obs, -3])

plot(rf_expl_sp,
     svm_expl_sp,
     lm_expl_sp)
```

### Exercise 3

```{r sol3}
library(shapleyr)

shapley_vals <- shapley(n_obs, house_task, house_rf_mlr)

gather(shapley_vals$values, "colname", "contribution") %>%
  filter(colname %in% colnames(houses)) %>%
  mutate(contribution = as.numeric(contribution)) %>%
  arrange(desc(abs(contribution)))
# alternatively use just
shapley_vals

class(shapley_vals) <- c("shapley.singleValue", "list")
plot(shapley_vals)
```


### Bonus 1

```{r solbonus1, warning = F, message = F}
rf_audit <- audit(rf_expl)
svm_audit <- audit(svm_expl)
lm_audit <- audit(lm_expl)

plotPrediction(rf_audit)
plotPrediction(svm_audit)
plotPrediction(lm_audit)
```

### Bonus 2

```{r bonsol3}
rf_global <- variable_importance(rf_expl)
plot(rf_global)
```

### Exercise 4

```{r sol4}
library(live)
library(mlr)

houses_similar <- sample_locally2(houses, houses[n_obs, ], "sqm_price", 1000)
houses_similar2 <- add_predictions2(houses_similar, house_rf)
lm_approx <- fit_explanation2(houses_similar2, "regr.lm")

lm_approx
```


### Exercise 5

```{r sol5}
plot_explanation2(lm_approx, regr_plot_type = "forest")
plot_explanation2(lm_approx, regr_plot_type = "waterfall")
```


### Exercise 6

```{r sol6}
library(lime)
lime_rf <- lime(houses, house_rf_mlr)
lime_explanation <- lime::explain(houses[n_obs, ], lime_rf, n_features = 5)
plot_features(lime_explanation)

plot(rf_expl_sp)
```


### Bonus 3

```{r bonsol2}
houses_similar3 <- add_predictions2(houses_similar, house_svm)
houses_similar4 <- add_predictions2(houses_similar, house_lm)
lm_approx2 <- fit_explanation2(houses_similar3)
lm_approx3 <- fit_explanation2(houses_similar4)

plot_explanation2(lm_approx2, "waterfall")
plot_explanation2(lm_approx3, "waterfall")

plot_explanation2(lm_approx2, "forest")
plot_explanation2(lm_approx3, "forest")
```



### Bonus 4

```{r bonsol4}
library(live)
library(mlr)
n_obs2 <- 5830
houses_similar <- sample_locally2(houses, houses[n_obs2, ], "sqm_price", 1000)
houses_similar2 <- add_predictions2(houses_similar, house_rf)
n_obs2expl <- fit_explanation2(houses_similar2)
n_obs2expl

plot_explanation2(n_obs2expl, "waterfall")

plot_explanation2(lm_approx, regr_plot_type = "waterfall")
```
